{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squeeze everything between 0 and 1\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "#helper to find gradient descent\n",
    "def sigmoid_p(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "def cost(target, prediction):\n",
    "    return (target - prediction)**2\n",
    "def cost_p(target, prediction):\n",
    "    return (target - prediction)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn():\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        self.biases = []\n",
    "        for i in range (1, len(sizes)):\n",
    "            bias = np.random.randn(sizes[i], 1)\n",
    "            self.biases.append(bias)\n",
    "            \n",
    "        self.weights = []\n",
    "        for i in range(1, len(sizes)):\n",
    "            weight = np.random.randn(sizes[i], sizes[i-1])\n",
    "            self.weights.append(weight)\n",
    "            \n",
    "        self.activations = []\n",
    "        for i in range (0, len(sizes)):\n",
    "            activation = np.zeros((sizes[i], 1))\n",
    "            self.activations.append(activation)\n",
    "    #vei avea XTrain[1], train se face pe fiecare\n",
    "    #element at inputului separat; deci se apeleaza intr-un for in care parcurgem data[i]\n",
    "    #si se realizeaza de iterations ori?\n",
    "    def compute_activations(self, input_data):\n",
    "        #input data o sa fie XTrain[row]\n",
    "        #for i in range(0, len(input_data)):\n",
    "        #print 'x' #vezi ca self ala poate face ceva\n",
    "        #si ar trebui sa lucrezi pe o copie?\n",
    "        for k in range(0, len(input_data)):\n",
    "            #print 'x'\n",
    "            self.activations[0][k] = input_data[k]\n",
    "        for i in range (1, len(self.activations)):\n",
    "        #acum suntem pe 4,4,3\n",
    "            for j in range(0, len(self.activations[i])):\n",
    "                s=0\n",
    "                #print activations[i][j], i, j, weights[i-1][j], biases[i-1][j], data,'kekeke'\n",
    "                x = zip(weights[i-1][j],input_data)\n",
    "                #print x, 'sdfsdg'\n",
    "                product = []\n",
    "                for element in x:\n",
    "                    product.append(element[0]*element[1])\n",
    "                #print product,'askdjjf'\n",
    "                for element in product:\n",
    "                    s = s + element\n",
    "                self.activations[i][j] = sigmoid(s)  \n",
    "        return self.activations\n",
    "    def backpropagate(self, input_data, output_data, learning_rate):\n",
    "        for i in xrange (len(weights),0, -1):\n",
    "            object = weights[i-1]\n",
    "            #ai weights citite de la ultimul\n",
    "            prediction = self.activations[i]\n",
    "            target = output_data\n",
    "            #print activations[i]\n",
    "            for j in xrange (0, len(object)):\n",
    "                target = output_data\n",
    "                dtotalcost_dz = cost_p(prediction[j], target[i-1])*sigmoid_p(activations[i][j])\n",
    "                dtotalcost_dweight = dtotalcost_dz*input_data[j]\n",
    "                weights[i-1][j] -= learning_rate*dtotalcost_dweight\n",
    "                biases[i-1][j] -= learning_rate*dtotalcost_dz*1.0\n",
    "        return weights, biases\n",
    "    def train(self, input_data, output_data, learning_rate, iterations):\n",
    "        while(iterations):\n",
    "            for i in range(0,len(input_data)):\n",
    "                data = input_data[i]\n",
    "                self.compute_activations(data)\n",
    "                self.backpropagate(data, output_data[i], learning_rate)\n",
    "            iterations-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.73445218],\n",
      "       [ 9.18823305],\n",
      "       [-4.7651804 ],\n",
      "       [-1.1754857 ]]), array([[-2.97345278],\n",
      "       [-7.05908509],\n",
      "       [ 4.45049136],\n",
      "       [ 0.18752715]]), array([[ 0.54948291],\n",
      "       [-2.72456766],\n",
      "       [-0.49587008]])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sizes = [8,4,4,3]\n",
    "in_data = [[5.1,3.5,1.4,0.2,5.1,3.5,1.4,0.2], \n",
    "[4.9,3.0,1.4,0.2,4.9,3.0,1.4,0.2],\n",
    "[4.7,3.2,1.3,0.2,4.7,3.2,1.3,0.2],\n",
    "[4.6,3.1,1.5,0.2,4.6,3.1,1.5,0.2],\n",
    "[5.0,3.6,1.4,0.2,5.0,3.6,1.4,0.2]]\n",
    "out_data = [[0,1,0],\n",
    "              [1,0,0],\n",
    "              [0,1,0],\n",
    "              [1,0,0],\n",
    "              [0,0,1]]\n",
    "\n",
    "obj = nn([8,4,4,3])\n",
    "obj.train(in_data, out_data, 0.2, 100)\n",
    "print biases\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2495373793333198\n",
      "-0.3819002048204532\n",
      "1.6866810461440935\n"
     ]
    }
   ],
   "source": [
    "\"\"\"activations = []\n",
    "#has to be computed for each iteration!\n",
    "for i in range (0, len(sizes)):\n",
    "    activation = np.zeros((sizes[i], 1))\n",
    "    activations.append(activation)\n",
    "#print activations, 'asklfhsdkjhfkjhes'\n",
    "activations = np.array(activations)\n",
    "#for j in range(0, len(input_data)): this will be\n",
    "#function that computes\n",
    "#def compute_activations(input_data):\n",
    "    #input data o sa fie XTrain[row]\n",
    "    #for i in range(0, len(input_data)):\n",
    "    #print 'x' #vezi ca self ala poate face ceva\n",
    "    #si ar trebui sa lucrezi pe o copie?\n",
    "    #for k in range(0, len(data)):\n",
    "        #print 'x'\n",
    "        #activations[0][k] = input_data[k]\n",
    "    #for i in range (1, len(activations)):\n",
    "    #acum suntem pe 4,4,3\n",
    "        #for j in range(0, len(activations[i])):\n",
    "            #s=0\n",
    "            #print activations[i][j], i, j, weights[i-1][j], biases[i-1][j], data,'kekeke'\n",
    "            #x = zip(weights[i-1][j],input_data)\n",
    "            #print x, 'sdfsdg'\n",
    "            product = []\n",
    "            for element in x:\n",
    "                product.append(element[0]*element[1])\n",
    "            #print product,'askdjjf'\n",
    "            for element in product:\n",
    "                s = s + element\n",
    "            #print s, 'maaai'\n",
    "            activations[i][j] = sigmoid(s)\n",
    "    return activations\n",
    "compute_activations(elm), 'dwf'\n",
    "for i in xrange (len(weights),0, -1):\n",
    "    object = weights[i-1]\n",
    "    #ai weights citite de la ultimul\n",
    "    prediction = activations[i]\n",
    "    #print activations[i]\n",
    "    #print target\n",
    "\n",
    "    for j in xrange (0, len(object)):\n",
    "        #current weight will be i-1\n",
    "        dtotalcost_dz = cost_p(prediction[j], target[i-1])*sigmoid_p(activations[i][j])\n",
    "        #print cost_p(prediction[j], target[i-1]), 'cost derivat'\n",
    "        #print sigmoid_p(activations[i][j]), 'sigm derv'\n",
    "        #print cost_p(prediction[j], target[i-1])*sigmoid_p(activations[i][j]), 'inmultirea lor'\n",
    "        obj = weights[i-1][j]\n",
    "        print obj[0]\n",
    "        break\n",
    "        #dtotalcost_dweight = dtotalcost_dz*input_data[i][j]\n",
    "        #weights[i-1][j] -= learning_rate*dtotalcost_dweight\n",
    "        #biases[i-1][j] -= learning_rate*dtotalcost_dz*1.0\n",
    "#print biases\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.32892007],\n",
      "       [-1.27123996],\n",
      "       [-0.26425067],\n",
      "       [-0.01402305]]), array([[-0.37348084],\n",
      "       [-1.11379043],\n",
      "       [-0.34287438],\n",
      "       [-0.46311924]]), array([[ 0.57616461],\n",
      "       [ 1.06745491],\n",
      "       [-0.05337157]])]\n",
      "[array([[-0.32895076],\n",
      "       [-1.27197562],\n",
      "       [-0.2642772 ],\n",
      "       [-0.13117933]]), array([[-0.37485252],\n",
      "       [-1.11608893],\n",
      "       [-0.34297119],\n",
      "       [-0.47852317]]), array([[ 0.57762997],\n",
      "       [ 1.06976937],\n",
      "       [-0.05260315]])]\n",
      "[array([[-0.32898144],\n",
      "       [-1.27271128],\n",
      "       [-0.26430373],\n",
      "       [-0.24833561]]), array([[-0.37622421],\n",
      "       [-1.11838743],\n",
      "       [-0.34306801],\n",
      "       [-0.49392711]]), array([[ 0.57909533],\n",
      "       [ 1.07208383],\n",
      "       [-0.05183473]])]\n",
      "[array([[-0.32901212],\n",
      "       [-1.27344693],\n",
      "       [-0.26433026],\n",
      "       [-0.36549189]]), array([[-0.37759589],\n",
      "       [-1.12068592],\n",
      "       [-0.34316482],\n",
      "       [-0.50933104]]), array([[ 0.58056068],\n",
      "       [ 1.07439829],\n",
      "       [-0.05106631]])]\n",
      "[array([[-0.32904281],\n",
      "       [-1.27418259],\n",
      "       [-0.26435679],\n",
      "       [-0.48264817]]), array([[-0.37896758],\n",
      "       [-1.12298442],\n",
      "       [-0.34326163],\n",
      "       [-0.52473497]]), array([[ 0.58202604],\n",
      "       [ 1.07671275],\n",
      "       [-0.05029789]])]\n",
      "[array([[-0.32907349],\n",
      "       [-1.27491825],\n",
      "       [-0.26438332],\n",
      "       [-0.59980445]]), array([[-0.38033926],\n",
      "       [-1.12528292],\n",
      "       [-0.34335845],\n",
      "       [-0.54013891]]), array([[ 0.58349139],\n",
      "       [ 1.07902721],\n",
      "       [-0.04952947]])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#while(iterations):\n",
    "learning_rate = 0.3\n",
    "totalcost = []\n",
    "for elm in range (0, len(input_data)):\n",
    "    data = input_data[elm]\n",
    "    target = output_data[elm]\n",
    "    #print target\n",
    "    #print data\n",
    "    activations = compute_activations(data)\n",
    "    #print activations\n",
    "    prediction = activations[-1]\n",
    "    #print prediction\n",
    "    s=0\n",
    "    s_p=0\n",
    "    for i in range(len(prediction)):\n",
    "        s = s + cost(prediction[i], target[i])\n",
    "        s_p = s_p + cost(prediction[i], target[i])\n",
    "    totalcost.append(s) #cost for first value in input_data is at index 0\n",
    "#print totalcost\n",
    "new_weights = weights\n",
    "\n",
    "\n",
    "#dont remember what this was for\n",
    "gradients = []\n",
    "for i in range (1, len(sizes)):\n",
    "    gradient = np.zeros((sizes[i], 1))\n",
    "    gradients.append(gradient)\n",
    "#print gradients\n",
    "#print totalcost[1], '\\n'\n",
    "#print biases[1], '\\n'\n",
    "#print weights, '\\n'\n",
    "#print 'activation:',activations, '\\n'\"\"\"\n",
    "\"\"\"So, now we have the total cost, weights, biases and all of that;\n",
    "We have to compute the new weights and biases accordingly\n",
    "parcurgem weights banuiesc, de la coada la cap; cost total derivat \"\"\" \n",
    "\"\"\"print biases\n",
    "for element in input_data:\n",
    "    for i in xrange (len(weights),0, -1):\n",
    "        object = weights[i-1]\n",
    "        #ai weights citite de la ultimul\n",
    "        prediction = activations[i]\n",
    "        #print activations[i]\n",
    "        #print target\n",
    "        for j in xrange (0, len(object)):\n",
    "            #current weight will be i-1\n",
    "            dtotalcost_dz = cost_p(prediction[j], target[i-1])*sigmoid_p(activations[i][j])\n",
    "            dtotalcost_dweight = dtotalcost_dz*input_data[i][j]\n",
    "            weights[i-1][j] -= learning_rate*dtotalcost_dweight\n",
    "            biases[i-1][j] -= learning_rate*dtotalcost_dz*1.0\n",
    "    print biases\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"    dtotalcost_dprediction = cost_p(target[i], prediction[i])\n",
    "        #prediction derived with respect to z\n",
    "        dprediction_dz = sigmoid_p(activations[i][j])\n",
    "        #then z with respect to our params w1, w2, b\n",
    "        dz_dweight = activation[i][j]\n",
    "        dz_dbias = 1 \n",
    "\n",
    "\n",
    "        dtotalcost_dz = dtotalcost_dprediction * dprediction_dz\n",
    "        dtotalcost_dweight = dtotalcost_dz * dz_dweight\n",
    "        dtotalcost_dbias = dtotalcost_dz * dz_dbias\n",
    "        #Aim: b = b - learning_rate * slope_of_cost(b); w1 = w1 - learning_rate * slope_of_cost(w1); w2 = w2 - learning_rate * slope_of_cost(w2)\n",
    "        weights[i][j] = weights[i][j] - learning_rate * dtotalcost_dweight\n",
    "        biases[i][j] = biases[i][j] - learning_rate * dtotalcost_dbias\n",
    "        \n",
    "\n",
    "        for j in range():\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "                #print N*change, M*self.co[j][k]\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
