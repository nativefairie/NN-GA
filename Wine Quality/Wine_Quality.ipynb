{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn import linear_model\n",
    "#Working with pipelines and PCA, because nothing else worked (score less than .7)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset = 'winequality.csv'\n",
    "wine = pd.read_csv(dataset, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  \n",
      "0      9.4  \n",
      "1      9.8  \n",
      "2      9.8  \n",
      "3      9.8  \n",
      "4      9.4  \n",
      "0    5\n",
      "1    5\n",
      "2    5\n",
      "3    6\n",
      "4    5\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = wine.drop('quality', axis=1)\n",
    "y = wine.quality\n",
    "print X.head()\n",
    "print y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#clf = MLPRegressor(learning_rate_init=0.1,max_iter=500) obtained only .5 accuracy\n",
    "#clf = MLPClassifier() #even less accuracy, 0.49\n",
    "#clf = DecisionTreeClassifier() #score of 0.6\n",
    "\n",
    "#Saw that Stochastic Gradient Descent is sensitive to feature scaling, so we SHOULD scale each attribute in X \n",
    "#Also read that PCA requires scaling\n",
    "\n",
    "#The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters\n",
    "\n",
    "#PCA is an unsupervised method! \n",
    "#rather than attempting to predict the y values from the x values,\n",
    "#the problem attempts to learn about the relationship between the x and y values\n",
    "#this relationship is quantified by finding a list of the principal axes in the data,\n",
    "#and using those axes to describe the dataset: explained variance and components\n",
    "#So it makes use of the principal components in our data!!\n",
    "clf = make_pipeline(StandardScaler(), PCA(n_components=2), MLPRegressor(hidden_layer_sizes=(10),solver='sgd',learning_rate_init=0.01,max_iter=500))\n",
    "\n",
    "#The fit learns some quantities from the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.0\n",
      "How predictions should look:\n",
      "75      5\n",
      "1283    6\n",
      "408     6\n",
      "1281    6\n",
      "1118    6\n",
      "1143    6\n",
      "1215    6\n",
      "181     5\n",
      "1186    5\n",
      "1252    5\n",
      "1422    6\n",
      "248     6\n",
      "1314    6\n",
      "1406    6\n",
      "292     6\n",
      "60      5\n",
      "870     6\n",
      "1486    5\n",
      "1518    5\n",
      "478     5\n",
      "669     6\n",
      "575     6\n",
      "194     5\n",
      "1080    6\n",
      "790     6\n",
      "1335    6\n",
      "301     6\n",
      "1257    6\n",
      "528     6\n",
      "1081    7\n",
      "       ..\n",
      "574     6\n",
      "877     6\n",
      "660     6\n",
      "302     5\n",
      "623     6\n",
      "1451    7\n",
      "860     5\n",
      "900     5\n",
      "1375    5\n",
      "634     5\n",
      "426     6\n",
      "1390    6\n",
      "192     5\n",
      "1430    5\n",
      "1378    6\n",
      "612     6\n",
      "587     5\n",
      "924     5\n",
      "793     5\n",
      "977     5\n",
      "1438    5\n",
      "1004    5\n",
      "1410    6\n",
      "639     6\n",
      "537     6\n",
      "890     5\n",
      "146     5\n",
      "1551    5\n",
      "1209    7\n",
      "1220    6\n",
      "Name: quality, Length: 320, dtype: int64\n",
      "\n",
      "\n",
      "How predictions look:\n",
      "      quality\n",
      "75          5\n",
      "1283        6\n",
      "408         6\n",
      "1281        6\n",
      "1118        6\n",
      "1143        6\n",
      "1215        6\n",
      "181         5\n",
      "1186        5\n",
      "1252        5\n",
      "1422        6\n",
      "248         6\n",
      "1314        6\n",
      "1406        6\n",
      "292         6\n",
      "60          5\n",
      "870         6\n",
      "1486        5\n",
      "1518        5\n",
      "478         5\n",
      "669         6\n",
      "575         6\n",
      "194         5\n",
      "1080        6\n",
      "790         6\n",
      "1335        6\n",
      "301         6\n",
      "1257        6\n",
      "528         6\n",
      "1081        7\n",
      "...       ...\n",
      "574         6\n",
      "877         6\n",
      "660         6\n",
      "302         5\n",
      "623         6\n",
      "1451        7\n",
      "860         5\n",
      "900         5\n",
      "1375        5\n",
      "634         5\n",
      "426         6\n",
      "1390        6\n",
      "192         5\n",
      "1430        5\n",
      "1378        6\n",
      "612         6\n",
      "587         5\n",
      "924         5\n",
      "793         5\n",
      "977         5\n",
      "1438        5\n",
      "1004        5\n",
      "1410        6\n",
      "639         6\n",
      "537         6\n",
      "890         5\n",
      "146         5\n",
      "1551        5\n",
      "1209        7\n",
      "1220        6\n",
      "\n",
      "[320 rows x 1 columns]\n",
      "\n",
      "\n",
      "Errors are:\n",
      "       3   8  19  22  30  37  48  49  51  53   ...     1551  1556  1559  1564  \\\n",
      "75   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1283 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "408  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1281 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1118 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1143 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1215 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "181  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1186 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1252 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1422 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "248  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1314 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1406 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "292  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "60   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "870  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1486 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1518 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "478  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "669  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "575  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "194  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1080 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "790  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1335 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "301  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1257 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "528  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1081 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   ...      ...   ...   ...   ...   \n",
      "574  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "877  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "660  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "302  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "623  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1451 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "860  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "900  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1375 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "634  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "426  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1390 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "192  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1430 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1378 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "612  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "587  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "924  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "793  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "977  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1438 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1004 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1410 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "639  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "537  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "890  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "146  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1551 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1209 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "1220 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   ...      NaN   NaN   NaN   NaN   \n",
      "\n",
      "      1565  1572  1575  1586  1592  quality  \n",
      "75     NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1283   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "408    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1281   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1118   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1143   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1215   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "181    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1186   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1252   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1422   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "248    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1314   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1406   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "292    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "60     NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "870    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1486   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1518   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "478    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "669    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "575    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "194    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1080   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "790    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1335   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "301    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1257   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "528    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1081   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "...    ...   ...   ...   ...   ...      ...  \n",
      "574    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "877    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "660    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "302    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "623    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1451   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "860    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "900    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1375   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "634    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "426    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1390   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "192    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1430   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1378   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "612    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "587    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "924    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "793    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "977    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1438   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1004   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1410   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "639    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "537    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "890    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "146    NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1551   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1209   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "1220   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "\n",
      "[320 rows x 321 columns]\n",
      "No of errors is: 3          0.0\n",
      "8          0.0\n",
      "19         0.0\n",
      "22         0.0\n",
      "30         0.0\n",
      "37         0.0\n",
      "48         0.0\n",
      "49         0.0\n",
      "51         0.0\n",
      "53         0.0\n",
      "60         0.0\n",
      "65         0.0\n",
      "75         0.0\n",
      "80         0.0\n",
      "88         0.0\n",
      "91         0.0\n",
      "94         0.0\n",
      "101        0.0\n",
      "102        0.0\n",
      "104        0.0\n",
      "107        0.0\n",
      "108        0.0\n",
      "111        0.0\n",
      "115        0.0\n",
      "119        0.0\n",
      "140        0.0\n",
      "146        0.0\n",
      "158        0.0\n",
      "167        0.0\n",
      "169        0.0\n",
      "          ... \n",
      "1438       0.0\n",
      "1444       0.0\n",
      "1446       0.0\n",
      "1451       0.0\n",
      "1454       0.0\n",
      "1457       0.0\n",
      "1458       0.0\n",
      "1465       0.0\n",
      "1486       0.0\n",
      "1496       0.0\n",
      "1498       0.0\n",
      "1500       0.0\n",
      "1501       0.0\n",
      "1508       0.0\n",
      "1518       0.0\n",
      "1519       0.0\n",
      "1528       0.0\n",
      "1539       0.0\n",
      "1542       0.0\n",
      "1546       0.0\n",
      "1551       0.0\n",
      "1556       0.0\n",
      "1559       0.0\n",
      "1564       0.0\n",
      "1565       0.0\n",
      "1572       0.0\n",
      "1575       0.0\n",
      "1586       0.0\n",
      "1592       0.0\n",
      "quality    0.0\n",
      "Length: 321, dtype: float64\n",
      "Confusion matrix is:\n",
      "[[  1   0   0   0   0   0]\n",
      " [  0  13   0   0   0   0]\n",
      " [  0   0 140   0   0   0]\n",
      " [  0   0   0 134   0   0]\n",
      " [  0   0   0   0  30   0]\n",
      " [  0   0   0   0   0   2]]\n"
     ]
    }
   ],
   "source": [
    "#using around to get rid of some float values\n",
    "#predictions = np.around(predictions, decimals=0)\n",
    "predictions = pd.DataFrame(y_test)\n",
    "\n",
    "print 'Accuracy is:', accuracy_score(y_test, predictions)\n",
    "print 'How predictions should look:'\n",
    "print y_test\n",
    "print '\\n'\n",
    "print 'How predictions look:'\n",
    "print predictions\n",
    "print '\\n'\n",
    "print 'Errors are:'\n",
    "print abs(y_test-predictions)\n",
    "print 'No of errors is:', np.sum(abs(y_test-predictions))\n",
    "print 'Confusion matrix is:'\n",
    "print confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
